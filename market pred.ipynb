{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- Work in progress..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-22T14:24:17.830522Z",
     "iopub.status.busy": "2022-01-22T14:24:17.830177Z",
     "iopub.status.idle": "2022-01-22T14:24:20.761284Z",
     "shell.execute_reply": "2022-01-22T14:24:20.760430Z",
     "shell.execute_reply.started": "2022-01-22T14:24:17.830430Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datatable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_79905/177421423.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[0;31m# linear algebra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;31m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdatatable\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datatable'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import datatable as dt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "import gc\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "cust_color = ['#fdc029',\n",
    "'#f7c14c',\n",
    "'#f0c268',\n",
    "'#e8c381',\n",
    "'#dfc498',\n",
    "'#d4c5af',\n",
    "'#c6c6c6',\n",
    "'#a6a6a8',\n",
    "'#86868a',\n",
    "'#68686d',\n",
    "'#4b4c52',\n",
    "'#303138',\n",
    "'#171820',\n",
    "]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (18,14)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"grid.color\"] = cust_color[3]\n",
    "plt.rcParams[\"grid.alpha\"] = 0.5\n",
    "plt.rcParams[\"grid.linestyle\"] = '--'\n",
    "plt.rcParams[\"font.family\"] = \"monospace\"\n",
    "\n",
    "plt.rcParams['axes.edgecolor'] = 'black'\n",
    "plt.rcParams['figure.frameon'] = False\n",
    "plt.rcParams['axes.spines.left'] = False\n",
    "plt.rcParams['axes.spines.bottom'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:24:20.763015Z",
     "iopub.status.busy": "2022-01-22T14:24:20.762817Z",
     "iopub.status.idle": "2022-01-22T14:26:12.677722Z",
     "shell.execute_reply": "2022-01-22T14:26:12.676580Z",
     "shell.execute_reply.started": "2022-01-22T14:24:20.762990Z"
    }
   },
   "outputs": [],
   "source": [
    "df = dt.fread('../input/ubiquant-market-prediction/train.csv').to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Look\n",
    "\n",
    "We have train, test and submission .csv's, let's take a look our train data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:12.679226Z",
     "iopub.status.busy": "2022-01-22T14:26:12.678966Z",
     "iopub.status.idle": "2022-01-22T14:26:12.736125Z",
     "shell.execute_reply": "2022-01-22T14:26:12.735145Z",
     "shell.execute_reply.started": "2022-01-22T14:26:12.679194Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:12.737912Z",
     "iopub.status.busy": "2022-01-22T14:26:12.737215Z",
     "iopub.status.idle": "2022-01-22T14:26:12.742902Z",
     "shell.execute_reply": "2022-01-22T14:26:12.741935Z",
     "shell.execute_reply.started": "2022-01-22T14:26:12.737871Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Train df number of instance: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:12.747275Z",
     "iopub.status.busy": "2022-01-22T14:26:12.746531Z",
     "iopub.status.idle": "2022-01-22T14:26:15.533678Z",
     "shell.execute_reply": "2022-01-22T14:26:15.532690Z",
     "shell.execute_reply.started": "2022-01-22T14:26:12.747225Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Train df missing value count: {df.isna().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:15.535101Z",
     "iopub.status.busy": "2022-01-22T14:26:15.534798Z",
     "iopub.status.idle": "2022-01-22T14:26:15.566315Z",
     "shell.execute_reply": "2022-01-22T14:26:15.565357Z",
     "shell.execute_reply.started": "2022-01-22T14:26:15.535070Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Train df number of unique investments: {df.investment_id.nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:15.568080Z",
     "iopub.status.busy": "2022-01-22T14:26:15.567770Z",
     "iopub.status.idle": "2022-01-22T14:26:15.590389Z",
     "shell.execute_reply": "2022-01-22T14:26:15.589443Z",
     "shell.execute_reply.started": "2022-01-22T14:26:15.568049Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Train df number of unique investments: {df.time_id.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems most of the investments ID's having 800+ timestamp records, while there are some having much less with left skewed distribution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:15.592291Z",
     "iopub.status.busy": "2022-01-22T14:26:15.591980Z",
     "iopub.status.idle": "2022-01-22T14:26:16.699089Z",
     "shell.execute_reply": "2022-01-22T14:26:16.698414Z",
     "shell.execute_reply.started": "2022-01-22T14:26:15.592252Z"
    }
   },
   "outputs": [],
   "source": [
    "time_count=df.groupby(\"investment_id\")['time_id'].count()\n",
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "sns.histplot(time_count, color=cust_color[-1], kde=True)\n",
    "plt.title('Number of time_id\\'s per Investment Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Sampling\n",
    "\n",
    "Since we have high number of instances (3141410) let's take some samples representing the actual population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:16.700969Z",
     "iopub.status.busy": "2022-01-22T14:26:16.700463Z",
     "iopub.status.idle": "2022-01-22T14:26:17.818200Z",
     "shell.execute_reply": "2022-01-22T14:26:17.817393Z",
     "shell.execute_reply.started": "2022-01-22T14:26:16.700934Z"
    }
   },
   "outputs": [],
   "source": [
    "sampled_df = df.sample(frac=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:17.819853Z",
     "iopub.status.busy": "2022-01-22T14:26:17.819417Z",
     "iopub.status.idle": "2022-01-22T14:26:17.824309Z",
     "shell.execute_reply": "2022-01-22T14:26:17.823055Z",
     "shell.execute_reply.started": "2022-01-22T14:26:17.819818Z"
    }
   },
   "outputs": [],
   "source": [
    "# from statsmodels.stats.weightstats import ztest\n",
    "# diff = np.mean(df.target) - np.mean(sampled_df.target)\n",
    "# t, p = ztest(df.target, x2=sampled_df.target, value=diff)\n",
    "# (np.nanmean(sampled_df.target) - np.nanmean(df.target)) / df.target.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:17.825790Z",
     "iopub.status.busy": "2022-01-22T14:26:17.825555Z",
     "iopub.status.idle": "2022-01-22T14:26:17.972279Z",
     "shell.execute_reply": "2022-01-22T14:26:17.971421Z",
     "shell.execute_reply.started": "2022-01-22T14:26:17.825761Z"
    }
   },
   "outputs": [],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting features \"float16\" to save some memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:17.973710Z",
     "iopub.status.busy": "2022-01-22T14:26:17.973449Z",
     "iopub.status.idle": "2022-01-22T14:26:37.463064Z",
     "shell.execute_reply": "2022-01-22T14:26:37.461801Z",
     "shell.execute_reply.started": "2022-01-22T14:26:17.973680Z"
    }
   },
   "outputs": [],
   "source": [
    "features = [f'f_{i}' for i in range(300)]\n",
    "\n",
    "for f in features:\n",
    "    sampled_df[f] = sampled_df[f].astype('float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:37.465310Z",
     "iopub.status.busy": "2022-01-22T14:26:37.464890Z",
     "iopub.status.idle": "2022-01-22T14:26:37.478939Z",
     "shell.execute_reply": "2022-01-22T14:26:37.477623Z",
     "shell.execute_reply.started": "2022-01-22T14:26:37.465109Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_dist3(df, feature, title):\n",
    "    \n",
    "    # Creating a customized chart. and giving in figsize and everything.\n",
    "    \n",
    "    fig = plt.figure(constrained_layout=True)\n",
    "    \n",
    "    # creating a grid of 3 cols and 3 rows.\n",
    "    \n",
    "    grid = gridspec.GridSpec(ncols=3, nrows=2, figure=fig)\n",
    "\n",
    "    # Customizing the histogram grid.\n",
    "    \n",
    "    ax1 = fig.add_subplot(grid[0, :2])\n",
    "    \n",
    "    # Set the title.\n",
    "    \n",
    "    ax1.set_title('Histogram')\n",
    "    \n",
    "    # plot the histogram.\n",
    "    \n",
    "    sns.distplot(df.loc[:, feature],\n",
    "                 hist=True,\n",
    "                 kde=True,\n",
    "                 fit=norm,\n",
    "                  hist_kws={\n",
    "                 'rwidth': 0.85,\n",
    "                 'edgecolor': 'black',\n",
    "                 'linewidth':.5,\n",
    "                 'alpha': 0.8},\n",
    "                 ax=ax1,\n",
    "                 color=cust_color[0])\n",
    "    \n",
    "    ax1.axvline(df.loc[:, feature].mean(), color='Green', linestyle='dashed', linewidth=3)\n",
    "\n",
    "    min_ylim, max_ylim = plt.ylim()\n",
    "    ax1.text(df.loc[:, feature].mean()*2, max_ylim*0.95, 'Mean: {:.2f}'.format(df.loc[:, feature].mean()), color='Green', fontsize='12',\n",
    "             bbox=dict(boxstyle='round',facecolor='red', alpha=0.5))\n",
    "    ax1.legend(labels=['Actual','Normal'])\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(nbins=12))\n",
    "    \n",
    "    ax2 = fig.add_subplot(grid[1, :2])\n",
    "    \n",
    "    # Set the title.\n",
    "    \n",
    "    ax2.set_title('Probability Plot')\n",
    "    \n",
    "    # Plotting the QQ_Plot.\n",
    "    stats.probplot(df.loc[:, feature],\n",
    "                   plot=ax2)\n",
    "    ax2.get_lines()[0].set_markerfacecolor('#e74c3c')\n",
    "    ax2.get_lines()[0].set_markersize(12.0)\n",
    "    ax2.xaxis.set_major_locator(MaxNLocator(nbins=16))\n",
    "\n",
    "    # Customizing the Box Plot:\n",
    "    \n",
    "    ax3 = fig.add_subplot(grid[:, 2])\n",
    "    # Set title.\n",
    "    \n",
    "    ax3.set_title('Box Plot')\n",
    "    \n",
    "    # Plotting the box plot.\n",
    "    \n",
    "    sns.boxplot(y=feature, data=df, ax=ax3, color=cust_color[0])\n",
    "    ax3.yaxis.set_major_locator(MaxNLocator(nbins=24))\n",
    "    #ax3.set_ylim(0,clip_value)\n",
    "\n",
    "    plt.suptitle(f'{title}', fontsize=24, fontname = 'monospace', weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:37.482356Z",
     "iopub.status.busy": "2022-01-22T14:26:37.481558Z",
     "iopub.status.idle": "2022-01-22T14:26:47.812787Z",
     "shell.execute_reply": "2022-01-22T14:26:47.811857Z",
     "shell.execute_reply.started": "2022-01-22T14:26:37.482316Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_dist3(sampled_df, 'target', 'Survey Duration Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target has decent distribution centered around 0 with a peak in the middle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some 'Odd' Feature Distributions\n",
    "\n",
    "These are the top features where their distribution doesn't fit \"normal\" standards. We mighty something useful four our models by looking at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:47.814322Z",
     "iopub.status.busy": "2022-01-22T14:26:47.814048Z",
     "iopub.status.idle": "2022-01-22T14:26:55.404339Z",
     "shell.execute_reply": "2022-01-22T14:26:55.402855Z",
     "shell.execute_reply.started": "2022-01-22T14:26:47.814289Z"
    }
   },
   "outputs": [],
   "source": [
    "features_std = sampled_df.iloc[:,4:].apply(lambda x: x.std()).sort_values(\n",
    "    ascending=False)\n",
    "f_std = sampled_df[features_std.iloc[:20].index.tolist()]\n",
    "\n",
    "features_skew = np.abs(sampled_df.iloc[:,4:].apply(lambda x: skew(x)).sort_values(\n",
    "    ascending=False))\n",
    "skewed = sampled_df[features_skew.iloc[:20].index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:55.406364Z",
     "iopub.status.busy": "2022-01-22T14:26:55.406106Z",
     "iopub.status.idle": "2022-01-22T14:26:55.414657Z",
     "shell.execute_reply": "2022-01-22T14:26:55.413207Z",
     "shell.execute_reply.started": "2022-01-22T14:26:55.406332Z"
    }
   },
   "outputs": [],
   "source": [
    "def feat_dist(df, cols, rows=3, columns=3, title=None):\n",
    "    \n",
    "    '''A function for displaying skew feat distribution'''\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, columns, figsize=(30, 25), constrained_layout=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, j in zip(cols, axes):\n",
    "        sns.distplot(\n",
    "                    df[i],\n",
    "                    ax=j,\n",
    "                    fit=norm,\n",
    "                    hist=False,\n",
    "                    color=cust_color[3],\n",
    "                    kde_kws={'linewidth':3}\n",
    "        )   \n",
    "        \n",
    "        (mu, sigma) = norm.fit(df[i])\n",
    "        j.set_title('Dist of {0} Norm Fit: $\\mu=${1:.2g}, $\\sigma=${2:.2f}'.format(i, mu, sigma), weight='bold')\n",
    "        j.legend(labels=[f'{i}', 'Normal Dist'])\n",
    "        fig.suptitle(f'{title}', fontsize=24, weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:26:55.417491Z",
     "iopub.status.busy": "2022-01-22T14:26:55.416740Z",
     "iopub.status.idle": "2022-01-22T14:27:21.390115Z",
     "shell.execute_reply": "2022-01-22T14:27:21.388898Z",
     "shell.execute_reply.started": "2022-01-22T14:26:55.417439Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_dist(sampled_df, f_std.columns.tolist(), rows=5, columns=4, title='Distribution of High Std Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:27:21.392542Z",
     "iopub.status.busy": "2022-01-22T14:27:21.391470Z",
     "iopub.status.idle": "2022-01-22T14:27:45.607635Z",
     "shell.execute_reply": "2022-01-22T14:27:45.606725Z",
     "shell.execute_reply.started": "2022-01-22T14:27:21.392448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating distplot of features which has high skewness\n",
    "\n",
    "feat_dist(sampled_df, skewed.columns.tolist(), rows=5, columns=4, title='Distribution of Skewed Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Target Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:27:45.609942Z",
     "iopub.status.busy": "2022-01-22T14:27:45.609038Z",
     "iopub.status.idle": "2022-01-22T14:27:47.448265Z",
     "shell.execute_reply": "2022-01-22T14:27:47.447634Z",
     "shell.execute_reply.started": "2022-01-22T14:27:45.609896Z"
    }
   },
   "outputs": [],
   "source": [
    "correlations = sampled_df.corrwith(sampled_df['target']).iloc[:-1].to_frame()\n",
    "correlations['Abs Corr'] = correlations[0].abs()\n",
    "sorted_correlations = correlations.sort_values('Abs Corr', ascending=False)['Abs Corr']\n",
    "fig, ax = plt.subplots(figsize=(6,8))\n",
    "sns.heatmap(sorted_correlations.iloc[1:].to_frame()[sorted_correlations>=.04], cmap='coolwarm', annot=True, vmin=-1, vmax=1, ax=ax)\n",
    "plt.title('Feature Correlations With Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost no linear correlation between features and target..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Between Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:27:47.450012Z",
     "iopub.status.busy": "2022-01-22T14:27:47.449558Z",
     "iopub.status.idle": "2022-01-22T14:28:32.457539Z",
     "shell.execute_reply": "2022-01-22T14:28:32.456323Z",
     "shell.execute_reply.started": "2022-01-22T14:27:47.449979Z"
    }
   },
   "outputs": [],
   "source": [
    "corr = sampled_df.iloc[:, 4:].corr()\n",
    "sns.clustermap(corr, metric=\"correlation\", cmap=\"Reds\", figsize=(20, 20))\n",
    "plt.suptitle('Correlations Between Features', fontsize=24, weight='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations Between Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:28:32.459829Z",
     "iopub.status.busy": "2022-01-22T14:28:32.459511Z",
     "iopub.status.idle": "2022-01-22T14:28:32.523312Z",
     "shell.execute_reply": "2022-01-22T14:28:32.522651Z",
     "shell.execute_reply.started": "2022-01-22T14:28:32.459789Z"
    }
   },
   "outputs": [],
   "source": [
    "corr = corr.abs()\n",
    "\n",
    "corrs = corr.unstack()\n",
    "pair = corrs.sort_values(ascending=False)\n",
    "pair = pair.reset_index(name='correlation').rename(columns={'level_0': 'feature_a', 'level_1': 'feature_b', 0: 'correlation'})\n",
    "pair = pair[pair['feature_a'] != pair['feature_b']].iloc[::2,:]\n",
    "pair = pair[:10]\n",
    "pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there are some strongly correlated features. Let's take a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:28:32.525244Z",
     "iopub.status.busy": "2022-01-22T14:28:32.524566Z",
     "iopub.status.idle": "2022-01-22T14:28:58.821319Z",
     "shell.execute_reply": "2022-01-22T14:28:58.820409Z",
     "shell.execute_reply.started": "2022-01-22T14:28:32.525209Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(sampled_df[pair['feature_a'].iloc[0]], sampled_df[pair['feature_b'].iloc[0]], kind=\"reg\", color=cust_color[0], height=8,\n",
    "              joint_kws={'scatter_kws':dict(alpha=0.5, edgecolor=\"r\", linewidth=0.5)})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah linearity there for some features, let's take a look at the general picture with hexbins since there are many points to scatter this might show it better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-22T14:28:58.822928Z",
     "iopub.status.busy": "2022-01-22T14:28:58.822655Z",
     "iopub.status.idle": "2022-01-22T14:28:58.833034Z",
     "shell.execute_reply": "2022-01-22T14:28:58.832185Z",
     "shell.execute_reply.started": "2022-01-22T14:28:58.822892Z"
    }
   },
   "outputs": [],
   "source": [
    "def hex_plot(df, rows=3, columns=3, title=None):\n",
    "    \n",
    "    '''A function for displaying skew feat distribution'''\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, columns, figsize=(30, 25), constrained_layout=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i,j in enumerate(axes):\n",
    "        j.hexbin(sampled_df[pair['feature_a'].iloc[i]], sampled_df[pair['feature_b'].iloc[i]],  gridsize=100, cmap='Reds', bins='log')\n",
    "        j.set_xlabel(pair['feature_a'].iloc[i])\n",
    "        j.set_ylabel(pair['feature_b'].iloc[i])\n",
    "\n",
    "        fig.suptitle(f'{title}', fontsize=24, weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:28:58.835085Z",
     "iopub.status.busy": "2022-01-22T14:28:58.834551Z",
     "iopub.status.idle": "2022-01-22T14:29:11.764024Z",
     "shell.execute_reply": "2022-01-22T14:29:11.762698Z",
     "shell.execute_reply.started": "2022-01-22T14:28:58.835047Z"
    }
   },
   "outputs": [],
   "source": [
    "hex_plot(sampled_df, rows=5, columns=2, title='Highly Correlated Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see there are strong linear correlations between some features either negative or positive. Since we have kind of a regression problem in our hands we should take a closer look to these variables to prevent multicollinearity..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction and Clusters\n",
    "\n",
    "Since the data is anonymized and lacking categorical variables we might want to look at some reduced dimension plots and use some unsupervised techniques to see if we can find some patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:29:11.765862Z",
     "iopub.status.busy": "2022-01-22T14:29:11.765473Z",
     "iopub.status.idle": "2022-01-22T14:29:28.353942Z",
     "shell.execute_reply": "2022-01-22T14:29:28.352856Z",
     "shell.execute_reply.started": "2022-01-22T14:29:11.765828Z"
    }
   },
   "outputs": [],
   "source": [
    "features = sampled_df.iloc[:, 4:].columns.tolist()\n",
    "\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('pca', PCA())])\n",
    "pipe.fit(sampled_df[features])\n",
    "pca_samples = pipe.transform(sampled_df[features])\n",
    "\n",
    "# explaining variance ratio:\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "plt.plot(range(sampled_df[features].shape[1]), pipe.named_steps['pca'].explained_variance_ratio_.cumsum(), linestyle='--', drawstyle='steps-mid', color=cust_color[-1],\n",
    "         label='Cumulative Explained Variance', linewidth = 1.5)\n",
    "sns.barplot(np.arange(1,sampled_df[features].shape[1]+1), pipe.named_steps['pca'].explained_variance_ratio_, alpha=0.85, color=cust_color[0],\n",
    "            label='Individual Explained Variance', edgecolor='black', saturation = 2, linewidth = 0.5)\n",
    "\n",
    "plt.ylabel('Explained Variance Ratio', fontsize = 14, fontname = 'monospace', weight='semibold')\n",
    "plt.xlabel('Number of Principal Components', fontsize = 14, fontname = 'monospace', weight='semibold')\n",
    "ax.set_title('Explained Variance', fontsize = 20, fontname = 'monospace', weight='bold')\n",
    "plt.xticks(fontsize=8, rotation=90)\n",
    "plt.legend(fontsize = 13)\n",
    "plt.axis([0,99,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do have many features but it seems we cannot reduce them to lower value without losing some signals. To even explain the 80% variance we might have to use 100 principal components.\n",
    "\n",
    "Let's try our luck with clustering, maybe we can fit some instances into specific clusters so it can allow us to breakdown the problem and inspect different groups individualy. Let's see how many clusters we would need..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:29:28.355759Z",
     "iopub.status.busy": "2022-01-22T14:29:28.355514Z",
     "iopub.status.idle": "2022-01-22T14:31:42.619345Z",
     "shell.execute_reply": "2022-01-22T14:31:42.618388Z",
     "shell.execute_reply.started": "2022-01-22T14:29:28.355723Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans_per_k = [Pipeline([('scaler', StandardScaler()),('km', KMeans(n_clusters=k, random_state=42, max_iter=100, n_init=5, tol=1e-4))]).fit(sampled_df[features])\n",
    "                for k in range(1, 8)]\n",
    "inertias = [model.named_steps['km'].inertia_ for model in kmeans_per_k]\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "sns.lineplot(range(1, 8), inertias, color=cust_color[0], linewidth = 1.5)\n",
    "plt.xlabel(\"k\", fontsize=15)\n",
    "plt.ylabel(\"Inertia\", fontsize=15)\n",
    "\n",
    "plt.title('Inertias and n_clusters', fontname = 'monospace', weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, Doesn't look good... Anyways we have the sharpest elbow at k=2 but let's try k=4 it has also somewhat decent curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:31:42.621573Z",
     "iopub.status.busy": "2022-01-22T14:31:42.621079Z",
     "iopub.status.idle": "2022-01-22T14:32:47.136360Z",
     "shell.execute_reply": "2022-01-22T14:32:47.135643Z",
     "shell.execute_reply.started": "2022-01-22T14:31:42.621530Z"
    }
   },
   "outputs": [],
   "source": [
    "z  = Pipeline([('scaler', StandardScaler()),('km', KMeans(n_clusters=4, random_state=42, max_iter=100, tol=1e-4))]).fit(sampled_df[features])\n",
    "clusters = z.fit_predict(sampled_df[features])\n",
    "clusters=[str(number) for number in clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:32:47.137908Z",
     "iopub.status.busy": "2022-01-22T14:32:47.137480Z",
     "iopub.status.idle": "2022-01-22T14:33:06.815889Z",
     "shell.execute_reply": "2022-01-22T14:33:06.814825Z",
     "shell.execute_reply.started": "2022-01-22T14:32:47.137873Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()),('pca', PCA(n_components=2))])\n",
    "pipe.fit(sampled_df[features])\n",
    "pca_samples = pipe.transform(sampled_df[features])\n",
    "sns.scatterplot(pca_samples[:,0], pca_samples[:,1], hue=clusters)\n",
    "plt.title(\"Clusters on Reduced Dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well we have clusters but they don't mean much... Clusters are looking pretty close to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T14:33:06.817687Z",
     "iopub.status.busy": "2022-01-22T14:33:06.817402Z",
     "iopub.status.idle": "2022-01-22T14:33:18.426130Z",
     "shell.execute_reply": "2022-01-22T14:33:18.424465Z",
     "shell.execute_reply.started": "2022-01-22T14:33:06.817658Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()),('pca', PCA(n_components=4))])\n",
    "pipe.fit(sampled_df[features])\n",
    "pca_samples = pipe.transform(sampled_df[features])\n",
    "\n",
    "total_var = pipe.named_steps['pca'].explained_variance_ratio_.sum() * 100\n",
    "\n",
    "labels = {\n",
    "    str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
    "    for i, var in enumerate(pipe.named_steps['pca'].explained_variance_ratio_ * 100)\n",
    "}\n",
    "labels['color'] = 'Cluster'\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    pca_samples,\n",
    "    color=clusters,\n",
    "    dimensions=range(4),\n",
    "    labels=labels,\n",
    "    title=f'Total Explained Variance: {total_var:.2f}% by Clusters',\n",
    "    opacity=0.5\n",
    ")\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The picture doesn't change much when we plot components against each other too. Oh well...\n",
    "\n",
    "Next we should decide what method we can use to get some more insights using classical EDA techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work in Progress...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
